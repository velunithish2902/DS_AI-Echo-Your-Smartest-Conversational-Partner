{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#load the file in xlsx\n",
        "import pandas as pd\n",
        "df = pd.read_excel('/content/chatgpt_style_reviews_dataset.xlsx')\n",
        "print(df.head())"
      ],
      "metadata": {
        "collapsed": true,
        "id": "agx3O2PQF08z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()   # Column names, non-null counts, data types\n",
        "df.describe()  # Summary for numerical columns\n",
        "df.isnull().sum()  # Count missing values per column\n"
      ],
      "metadata": {
        "id": "mZY0gkvPF-L3",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#convert date column into date and time\n",
        "import pandas as pd\n",
        "\n",
        "df['date'] = pd.to_datetime(df['date'], errors='coerce')"
      ],
      "metadata": {
        "id": "31ivksUuGDNK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df.info()   # Column names, non-null counts, data types\n",
        "df.describe()  # Summary for numerical columns"
      ],
      "metadata": {
        "id": "NF5mbVthGFos"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "nltk.download('omw-1.4')"
      ],
      "metadata": {
        "id": "cYQBkW5pGIDM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import nltk\n",
        "import pandas as pd\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk import pos_tag\n",
        "from nltk.corpus import wordnet\n",
        "\n",
        "\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "negators = {\"no\",\"nor\",\"not\",\"don't\",\"ain\",\"aren\",\"couldn\",\"didn\",\"doesn\",\"hadn\",\"hasn\",\"haven\",\"isn\",\"mightn\",\"mustn\",\"needn\",\"shan\",\"shouldn\",\"wasn\",\"weren\",\"won\",\"wouldn\"}\n",
        "stop_words = stop_words - negators\n",
        "\n",
        "def _to_wn(pos):\n",
        "  return {\"J\": wordnet.ADJ, \"V\": wordnet.VERB, \"N\": wordnet.NOUN, \"R\": wordnet.ADV}.get(pos[0], wordnet.NOUN)\n",
        "\n",
        "def preprocess_text(text):\n",
        "\n",
        "    if pd.isnull(text):\n",
        "      return \"\"\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "    # Remove special characters and numbers\n",
        "    text = re.sub(r\"[^a-zA-Z\\s ']\", \" \", text)\n",
        "    #collapse extra spaces\n",
        "    text = re.sub(r\"\\s+\", \" \", text)\n",
        "    # Tokenize\n",
        "    tokens = text.split()\n",
        "    #remove stopwords but keep negators\n",
        "    tokens = [token for token in tokens if token not in stop_words or token in negators]\n",
        "    # Lemmatize\n",
        "    tagged_tokens = pos_tag(tokens)\n",
        "    lemmatized_tokens = [lemmatizer.lemmatize(token, _to_wn(pos)) for token, pos in tagged_tokens]\n",
        "    return \" \".join(lemmatized_tokens)\n",
        "\n",
        "df['cleaned_reviews']= df['review'].apply (preprocess_text)\n"
      ],
      "metadata": {
        "id": "NN-7BoxZGSWz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words"
      ],
      "metadata": {
        "id": "W9-_tq9zGZfk",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#fill missing value\n",
        "\n",
        "df.fillna({'title': 'No title', 'platform': 'Unknown'}, inplace=True)"
      ],
      "metadata": {
        "id": "zVQdPvUvGfap"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define mapping\n",
        "platform_map = {\n",
        "    \"App Store\": \"Mobile\",\n",
        "    \"Google Play\": \"Mobile\",\n",
        "    \"Flipkart\": \"Web\",\n",
        "    \"Amazon\": \"Web\"\n",
        "}\n",
        "\n",
        "# Apply mapping\n",
        "df['platform_grouped'] = df['platform'].map(platform_map)\n",
        "\n",
        "# If some values are not in map, mark them as 'Other'\n",
        "df['platform_grouped'] = df['platform_grouped'].fillna(\"Other\")\n",
        "\n",
        "print(df[['platform', 'platform_grouped']].head(10))\n",
        "print(df['platform_grouped'].value_counts())\n"
      ],
      "metadata": {
        "id": "rRaTgaHTGmok"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create sentiment labels from ratings\n",
        "def get_sentiment_label(rating):\n",
        "    if rating >= 4:\n",
        "        return 'positive'\n",
        "    elif rating <= 2:\n",
        "        return 'negative'\n",
        "    else:\n",
        "        return 'neutral'\n",
        "df['sentiment'] = df['rating'].apply(get_sentiment_label)"
      ],
      "metadata": {
        "id": "YIWJAn6aGrwA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df.info()\n",
        "df.head(3)"
      ],
      "metadata": {
        "id": "u7rXKAx4Gz8-",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#QUICK SANITY STAT\n",
        "print(\"Rows:\", len(df))\n",
        "print(\"Rating stats:\\n\", df[\"rating\"].describe())\n",
        "print(\"\\nSentiment distribution:\\n\", df[\"sentiment\"].value_counts(dropna=False))\n",
        "if \"platform\" in df.columns:\n",
        "    print(\"\\nPlatforms:\\n\", df[\"platform\"].value_counts().head())\n",
        "if \"location\" in df.columns:\n",
        "    print(\"\\nLocations:\\n\", df[\"location\"].value_counts().head())"
      ],
      "metadata": {
        "id": "ORfDzKjaG5FF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(columns=['username'], inplace=True)\n",
        "\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "id": "sXw9AwEEHFFz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#saving the data\n",
        "df.to_csv(\"processed_cleaned_reviews.csv\", index=False)\n",
        "print(\"Saved: processed_cleaned_reviews.csv\")\n"
      ],
      "metadata": {
        "id": "7htSQ-uuHHt6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Trained Machine Learning/DL Model for Sentiment Analysis\n",
        "# **installing requirements**"
      ],
      "metadata": {
        "id": "w12l9wuCHavI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip -q install pandas numpy scikit-learn matplotlib plotly wordcloud nltk\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')"
      ],
      "metadata": {
        "id": "tBwwTPDqHem4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score, cross_validate\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, classification_report, confusion_matrix,\n",
        "    roc_curve, auc, RocCurveDisplay,\n",
        "    precision_recall_curve, average_precision_score\n",
        ")\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from sklearn.dummy import DummyClassifier\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer"
      ],
      "metadata": {
        "id": "mmoLursCHk9F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# choose text column: prefer 'cleaned_review', else 'review'\n",
        "text_col = \"cleaned_reviews\" if \"cleaned_reviews\" in df.columns else \"review\"\n",
        "if text_col not in df.columns:\n",
        "    raise ValueError(\"Need a text column: 'cleaned_reviews' or 'review'\")\n",
        "\n",
        "# need a label; use 'sentiment' (Positive/Neutral/Negative). If missing, derive from rating.\n",
        "if \"sentiment\" not in df.columns:\n",
        "    if \"rating\" not in df.columns:\n",
        "        raise ValueError(\"Provide 'sentiment' or 'rating' to derive labels.\")\n",
        "    def assign_sentiment(r):\n",
        "        try:\n",
        "            r = float(r)\n",
        "        except:\n",
        "            return np.nan\n",
        "        if r >= 4: return \"Positive\"\n",
        "        if r == 3: return \"Neutral\"\n",
        "        if r <= 2: return \"Negative\"\n",
        "        return np.nan\n",
        "    df[\"sentiment\"] = df[\"rating\"].apply(assign_sentiment)\n",
        "\n",
        "# drop bad rows\n",
        "df_text = df[[text_col, \"sentiment\"]].dropna().copy()\n",
        "df_text[text_col] = df_text[text_col].astype(str)\n",
        "\n",
        "# (optional) quick cleaning if you used raw 'review'\n",
        "stop_words = set(stopwords.words(\"english\"))\n",
        "lemm = WordNetLemmatizer()\n",
        "\n",
        "def light_clean(x):\n",
        "    x = x.lower()\n",
        "    x = re.sub(r\"[^a-z\\s]\", \" \", x)\n",
        "    toks = [t for t in x.split() if t not in stop_words]\n",
        "    toks = [lemm.lemmatize(t) for t in toks]\n",
        "    return \" \".join(toks)\n",
        "\n",
        "if text_col == \"cleaned_reviews\":\n",
        "    df_text[\"text_proc\"] = df_text[text_col].apply(light_clean)\n",
        "    use_col = \"text_proc\"\n",
        "else:\n",
        "    use_col = text_col\n",
        "\n",
        "\n",
        "df_text.head(10)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "ISw_XgT3Hm_2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Sentiment analysis by NLTK\n",
        "\n",
        "\n",
        "import nltk\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "\n",
        "nltk.download('vader_lexicon')\n",
        "\n",
        "sia = SentimentIntensityAnalyzer()\n",
        "\n",
        "# Calculate polarity scores for each cleaned review and store them\n",
        "df['polarity_scores'] = df[\"cleaned_reviews\"].apply(sia.polarity_scores)\n",
        "\n",
        "# Display the first few rows with the new column\n",
        "print(df[['cleaned_reviews', 'polarity_scores']].head())\n",
        "\n",
        "#saving\n",
        "import joblib\n",
        "joblib.dump(sia, 'sentiment_analyzer.joblib')\n"
      ],
      "metadata": {
        "id": "UrxHxbiHH8bj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def get_sentiment_label(score):\n",
        "    if score['compound'] >= 0.05:\n",
        "        return \"Positive\"\n",
        "    elif score['compound'] <= -0.05:\n",
        "        return \"Negative\"\n",
        "    else:\n",
        "        return \"Neutral\"\n",
        "\n",
        "df['sentiment'] = df['polarity_scores'].apply(get_sentiment_label)\n"
      ],
      "metadata": {
        "id": "xPy2KAAnIFGx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df.head()\n"
      ],
      "metadata": {
        "id": "9wUSP309IJ8C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#saving as csv updated\n",
        "df.to_csv(\"cleaned_reviews.csv\", index=False)\n",
        "print(\"Saved: cleaned_reviews.csv\")"
      ],
      "metadata": {
        "id": "UeTptR0PIRwv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_text.columns)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7aHpFuvEIrjD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "removed_classes = df_text[\"sentiment\"].value_counts()[df_text[\"sentiment\"].value_counts() < 2]\n",
        "print(\"Removed classes:\", removed_classes.index.tolist())"
      ],
      "metadata": {
        "id": "zxSD6fUOI9We"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "logistic regression pipeline\n",
        "\n"
      ],
      "metadata": {
        "id": "R9U4vdzCJRxY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# balance_and_train.py\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.utils import resample\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import joblib"
      ],
      "metadata": {
        "id": "0WSbdQWkdYLK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ---------- LOAD your CSV ----------\n",
        "# change path/column names as needed\n",
        "df = pd.read_csv('/content/processed_cleaned_reviews.csv')\n",
        "# assume df has columns: 'cleaned_reviews' (text) and 'sentiment' (labels: 'positive','neutral','negative')\n",
        "df = df[['cleaned_reviews','sentiment']].dropna()"
      ],
      "metadata": {
        "id": "2wyBqH4Ddd5n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- Inspect counts (optional) ----------\n",
        "print(\"Before:\", df['sentiment'].value_counts())\n"
      ],
      "metadata": {
        "id": "_f1CZeiRdiyD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- UPSAMPLE to balance ----------\n",
        "# target: match the maximum class count\n",
        "max_count = df['sentiment'].value_counts().max()\n",
        "\n",
        "balanced_parts = []\n",
        "for label, group in df.groupby('sentiment'):\n",
        "    if len(group) < max_count:\n",
        "        up = resample(group,\n",
        "                      replace=True,\n",
        "                      n_samples=max_count,\n",
        "                      random_state=42)\n",
        "        balanced_parts.append(up)\n",
        "    else:\n",
        "        balanced_parts.append(group)\n",
        "\n",
        "df_balanced = pd.concat(balanced_parts).sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "print(\"After:\", df_balanced['sentiment'].value_counts())\n"
      ],
      "metadata": {
        "id": "XA9Q8cVmdn1q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- Train / Test split ----------\n",
        "X = df_balanced['cleaned_reviews'].astype(str)\n",
        "y = df_balanced['sentiment']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, stratify=y, random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "tFWEBcBVdwOW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- Vectorize ----------\n",
        "vectorizer = TfidfVectorizer(max_features=20000, ngram_range=(1,2))\n",
        "X_train_vec = vectorizer.fit_transform(X_train)\n",
        "X_test_vec = vectorizer.transform(X_test)"
      ],
      "metadata": {
        "id": "VThswpMydzHk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- Model (Logistic Regression) ----------\n",
        "model = LogisticRegression(max_iter=1000, class_weight=None, solver='liblinear', random_state=42)\n",
        "# (class_weight=None because we've balanced data; if you DON'T balance, use class_weight='balanced')"
      ],
      "metadata": {
        "id": "vnOFzq9vd3O6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# quick cross-val on training data\n",
        "cv_scores = cross_val_score(model, X_train_vec, y_train, cv=5, scoring='accuracy')\n",
        "print(\"CV accuracy (train):\", cv_scores.mean(), cv_scores)"
      ],
      "metadata": {
        "id": "SqpoYvrGd7fj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# fit final model\n",
        "model.fit(X_train_vec, y_train)"
      ],
      "metadata": {
        "id": "zPv1oQTgd_mo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- Evaluation ----------\n",
        "y_pred = model.predict(X_test_vec)\n",
        "print(\"Classification report (test):\\n\", classification_report(y_test, y_pred))\n",
        "print(\"Confusion matrix:\\n\", confusion_matrix(y_test, y_pred))"
      ],
      "metadata": {
        "id": "VC_PLOGreN2-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- Save model + vectorizer ----------\n",
        "joblib.dump(model, \"text_classifier_balanced.joblib\")\n",
        "joblib.dump(vectorizer, \"vectorizer_balanced.joblib\")\n",
        "print(\"Saved model -> text_classifier_balanced.joblib\")\n",
        "print(\"Saved vectorizer -> vectorizer_balanced.joblib\")\n"
      ],
      "metadata": {
        "id": "L33D4EK9em0W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **checking**"
      ],
      "metadata": {
        "id": "oM_rZnMngILy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk"
      ],
      "metadata": {
        "id": "OKaha2sTbw1L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install libraries\n",
        "#!pip install nltk\n",
        "\n",
        "import nltk\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "\n",
        "# Download VADER lexicon\n",
        "nltk.download('vader_lexicon')\n",
        "\n",
        "# Initialize VADER\n",
        "sid = SentimentIntensityAnalyzer()\n",
        "\n",
        "# Custom sentiment word lists\n",
        "custom_positive = {\n",
        "    \"good\", \"great\", \"excellent\", \"love\", \"awesome\", \"fast\",\n",
        "    \"smooth\", \"best\", \"amazing\", \"perfect\", \"nice\", \"better\",\n",
        "    \"fantastic\", \"wonderful\", \"super\"\n",
        "}\n",
        "\n",
        "custom_negative = {\n",
        "    \"bad\", \"worst\", \"poor\", \"crash\", \"crashes\", \"error\",\n",
        "    \"slow\", \"terrible\", \"problem\", \"problems\", \"issue\",\n",
        "    \"issues\", \"bug\", \"bugs\", \"fail\", \"failed\", \"lag\", \"laggy\"\n",
        "}\n",
        "\n",
        "custom_neutral = {\n",
        "    \"acceptable\", \"average\", \"ok\", \"okay\", \"fine\", \"decent\",\n",
        "    \"normal\", \"regular\", \"usual\", \"overall\"\n",
        "}\n",
        "\n",
        "# -----------------------------\n",
        "# WORD SENTIMENT FUNCTION\n",
        "# -----------------------------\n",
        "def word_sentiment(text):\n",
        "    words = text.split()\n",
        "    results = {}\n",
        "\n",
        "    for w in words:\n",
        "        clean = w.lower().strip(\",.!?\")\n",
        "\n",
        "        if clean in custom_neutral:\n",
        "            results[w] = \"Neutral\"\n",
        "            continue\n",
        "        if clean in custom_positive:\n",
        "            results[w] = \"Positive\"\n",
        "            continue\n",
        "        if clean in custom_negative:\n",
        "            results[w] = \"Negative\"\n",
        "            continue\n",
        "\n",
        "        # VADER fallback\n",
        "        score = sid.polarity_scores(clean)[\"compound\"]\n",
        "        if score > 0.05:\n",
        "            results[w] = \"Positive\"\n",
        "        elif score < -0.05:\n",
        "            results[w] = \"Negative\"\n",
        "        else:\n",
        "            results[w] = \"Neutral\"\n",
        "\n",
        "    return results\n",
        "\n",
        "# -----------------------------\n",
        "# FINAL SENTENCE SENTIMENT\n",
        "# -----------------------------\n",
        "def final_sentiment(text):\n",
        "    w = word_sentiment(text)\n",
        "\n",
        "    pos = sum(1 for v in w.values() if v == \"Positive\")\n",
        "    neg = sum(1 for v in w.values() if v == \"Negative\")\n",
        "\n",
        "    # Rule-based hybrid\n",
        "    if pos > neg:\n",
        "        return \"Positive\"\n",
        "    elif neg > pos:\n",
        "        return \"Negative\"\n",
        "    else:\n",
        "        return \"Neutral\"\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# ðŸ”¥ RUN & ENTER SENTENCE\n",
        "# -----------------------------\n",
        "sentence = input(\"Enter a sentence: \")\n",
        "\n",
        "print(\"\\nWORD-LEVEL SENTIMENT:\")\n",
        "print(word_sentiment(sentence))\n",
        "\n",
        "print(\"\\nFINAL SENTENCE SENTIMENT:\")\n",
        "print(final_sentiment(sentence))\n"
      ],
      "metadata": {
        "id": "KkrIKUI4aRt1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "scv-VWSyZkht"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}